{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sisyphus2.backend import analysis, visualizations, simulation_tools\n",
    "from sisyphus2.backend.networks import Model\n",
    "from sisyphus2.tasks import task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdm = task.rdm2(stim_noise = 0.02, coherences = np.linspace(.01, .2, 100), rec_noise = .01, N_rec = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = rdm.generate_train_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = rdm.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params['load_weights_path'] = '../weights/rdm_10_rec.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'weights_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a3827dfd7629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weights_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'weights_path'"
     ]
    }
   ],
   "source": [
    "params['load_weights_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_function(loss, step):\n",
    "    \n",
    "    cohs = [.1] * 400 + [.05] * 400 + [.02] * 400 + [.01] * 400\n",
    "    \n",
    "    r = task.rdm2(stim_noise = 0.02, coherences = np.linspace(.001, cohs[step/10], 100), rec_noise = .01, N_rec = 5)\n",
    "    gen = r.generate_train_trials()\n",
    "    \n",
    "    return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 640, Minibatch Loss= 0.343267\n",
      "Iter 1280, Minibatch Loss= 0.149323\n",
      "Iter 1920, Minibatch Loss= 0.276039\n",
      "Iter 2560, Minibatch Loss= 0.184335\n",
      "Iter 3200, Minibatch Loss= 0.082115\n",
      "Iter 3840, Minibatch Loss= 0.153617\n",
      "Iter 4480, Minibatch Loss= 0.075405\n",
      "Iter 5120, Minibatch Loss= 0.182589\n",
      "Iter 5760, Minibatch Loss= 0.157587\n",
      "Iter 6400, Minibatch Loss= 0.135918\n",
      "Iter 7040, Minibatch Loss= 0.104852\n",
      "Iter 7680, Minibatch Loss= 0.121696\n",
      "Iter 8320, Minibatch Loss= 0.137726\n",
      "Iter 8960, Minibatch Loss= 0.181608\n",
      "Iter 9600, Minibatch Loss= 0.106897\n",
      "Iter 10240, Minibatch Loss= 0.090758\n",
      "Iter 10880, Minibatch Loss= 0.109229\n",
      "Iter 11520, Minibatch Loss= 0.080260\n",
      "Iter 12160, Minibatch Loss= 0.197645\n",
      "Iter 12800, Minibatch Loss= 0.155636\n",
      "Iter 13440, Minibatch Loss= 0.070826\n",
      "Iter 14080, Minibatch Loss= 0.101790\n",
      "Iter 14720, Minibatch Loss= 0.114157\n",
      "Iter 15360, Minibatch Loss= 0.080499\n",
      "Iter 16000, Minibatch Loss= 0.143107\n",
      "Iter 16640, Minibatch Loss= 0.070764\n",
      "Iter 17280, Minibatch Loss= 0.090903\n",
      "Iter 17920, Minibatch Loss= 0.149354\n",
      "Iter 18560, Minibatch Loss= 0.155957\n",
      "Iter 19200, Minibatch Loss= 0.086162\n",
      "Iter 19840, Minibatch Loss= 0.135976\n",
      "Iter 20480, Minibatch Loss= 0.159188\n",
      "Iter 21120, Minibatch Loss= 0.128343\n",
      "Iter 21760, Minibatch Loss= 0.101949\n",
      "Iter 22400, Minibatch Loss= 0.167815\n",
      "Iter 23040, Minibatch Loss= 0.062825\n",
      "Iter 23680, Minibatch Loss= 0.101237\n",
      "Iter 24320, Minibatch Loss= 0.109660\n",
      "Iter 24960, Minibatch Loss= 0.156814\n",
      "Iter 25600, Minibatch Loss= 0.116799\n",
      "Iter 26240, Minibatch Loss= 0.137237\n",
      "Iter 26880, Minibatch Loss= 0.179253\n",
      "Iter 27520, Minibatch Loss= 0.147532\n",
      "Iter 28160, Minibatch Loss= 0.104995\n",
      "Iter 28800, Minibatch Loss= 0.100797\n",
      "Iter 29440, Minibatch Loss= 0.174927\n",
      "Iter 30080, Minibatch Loss= 0.131612\n",
      "Iter 30720, Minibatch Loss= 0.067916\n",
      "Iter 31360, Minibatch Loss= 0.146979\n",
      "Iter 32000, Minibatch Loss= 0.116582\n",
      "Iter 32640, Minibatch Loss= 0.087812\n",
      "Iter 33280, Minibatch Loss= 0.068835\n",
      "Iter 33920, Minibatch Loss= 0.143239\n",
      "Iter 34560, Minibatch Loss= 0.066107\n",
      "Iter 35200, Minibatch Loss= 0.069337\n",
      "Iter 35840, Minibatch Loss= 0.119116\n",
      "Iter 36480, Minibatch Loss= 0.177696\n",
      "Iter 37120, Minibatch Loss= 0.100315\n",
      "Iter 37760, Minibatch Loss= 0.102061\n",
      "Iter 38400, Minibatch Loss= 0.131958\n",
      "Iter 39040, Minibatch Loss= 0.089120\n",
      "Iter 39680, Minibatch Loss= 0.141399\n",
      "Iter 40320, Minibatch Loss= 0.165008\n",
      "Iter 40960, Minibatch Loss= 0.083915\n",
      "Iter 41600, Minibatch Loss= 0.074531\n",
      "Iter 42240, Minibatch Loss= 0.063212\n",
      "Iter 42880, Minibatch Loss= 0.060493\n",
      "Iter 43520, Minibatch Loss= 0.067392\n",
      "Iter 44160, Minibatch Loss= 0.138567\n",
      "Iter 44800, Minibatch Loss= 0.143260\n",
      "Iter 45440, Minibatch Loss= 0.075355\n",
      "Iter 46080, Minibatch Loss= 0.079211\n",
      "Iter 46720, Minibatch Loss= 0.144220\n",
      "Iter 47360, Minibatch Loss= 0.165208\n",
      "Iter 48000, Minibatch Loss= 0.174553\n",
      "Iter 48640, Minibatch Loss= 0.171450\n",
      "Iter 49280, Minibatch Loss= 0.159353\n",
      "Iter 49920, Minibatch Loss= 0.069075\n",
      "Iter 50560, Minibatch Loss= 0.103223\n",
      "Iter 51200, Minibatch Loss= 0.111525\n",
      "Iter 51840, Minibatch Loss= 0.066838\n",
      "Iter 52480, Minibatch Loss= 0.131354\n",
      "Iter 53120, Minibatch Loss= 0.117539\n",
      "Iter 53760, Minibatch Loss= 0.150063\n",
      "Iter 54400, Minibatch Loss= 0.131029\n",
      "Iter 55040, Minibatch Loss= 0.148285\n",
      "Iter 55680, Minibatch Loss= 0.137120\n",
      "Iter 56320, Minibatch Loss= 0.082405\n",
      "Iter 56960, Minibatch Loss= 0.066196\n",
      "Iter 57600, Minibatch Loss= 0.074086\n",
      "Iter 58240, Minibatch Loss= 0.161971\n",
      "Iter 58880, Minibatch Loss= 0.060848\n",
      "Iter 59520, Minibatch Loss= 0.095619\n",
      "Iter 60160, Minibatch Loss= 0.113909\n",
      "Iter 60800, Minibatch Loss= 0.059584\n",
      "Iter 61440, Minibatch Loss= 0.076417\n",
      "Iter 62080, Minibatch Loss= 0.145019\n",
      "Iter 62720, Minibatch Loss= 0.081345\n",
      "Iter 63360, Minibatch Loss= 0.149558\n",
      "Iter 64000, Minibatch Loss= 0.092935\n",
      "Iter 64640, Minibatch Loss= 0.089148\n",
      "Iter 65280, Minibatch Loss= 0.148615\n",
      "Iter 65920, Minibatch Loss= 0.061942\n",
      "Iter 66560, Minibatch Loss= 0.090753\n",
      "Iter 67200, Minibatch Loss= 0.159221\n",
      "Iter 67840, Minibatch Loss= 0.077512\n",
      "Iter 68480, Minibatch Loss= 0.097535\n",
      "Iter 69120, Minibatch Loss= 0.171371\n",
      "Iter 69760, Minibatch Loss= 0.103990\n",
      "Iter 70400, Minibatch Loss= 0.091276\n",
      "Iter 71040, Minibatch Loss= 0.168791\n",
      "Iter 71680, Minibatch Loss= 0.093044\n",
      "Iter 72320, Minibatch Loss= 0.061555\n",
      "Iter 72960, Minibatch Loss= 0.064147\n",
      "Iter 73600, Minibatch Loss= 0.151692\n",
      "Iter 74240, Minibatch Loss= 0.131149\n",
      "Iter 74880, Minibatch Loss= 0.140817\n"
     ]
    }
   ],
   "source": [
    "model = Model(params)\n",
    "learning_rate = .001 \n",
    "training_iters = 1000000\n",
    "weights_path = '../weights/rdm_david.npz'\n",
    "sess = tf.Session()\n",
    "model.train(sess, gen, learning_rate = learning_rate, \n",
    "            training_iters = training_iters, weights_path = weights_path, generator_function = generator_function)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
